**AI-Based Sign Language Translator**

**Overview**

The **AI-Based Sign Language Translator** is a computer vision project that detects and recognizes hand gestures in real time, converting them into corresponding letters, words, and speech.  
Currently, the system supports **5 letters**, with scope for expansion to the entire alphabet and numerals.

This project aims to bridge the communication gap between the deaf/mute community and others, making conversations more inclusive and accessible.

**Features**
-  **Real-time gesture detection** using a webcam.
-  Recognition of **5 sign language letters**.
-  Converts recognized letters into **speech output**.
-  **Fast and lightweight** — works in real time.
-  Clean, simple, and user-friendly interface.

**Tech Stack**
- **Python**
- **OpenCV** – for image capture and processing
- **MediaPipe** – for hand tracking
- **TensorFlow/Keras** – for gesture classification
- **Pyttsx3** – for text-to-speech conversion

